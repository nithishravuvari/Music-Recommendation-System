{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Import libraries ------------------\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"spotify_millsongdata.csv\")\n",
    "df = df.sample(5000).drop('link', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nitis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nitis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')  # <-- NEW in NLTK >= 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Verify tokenizer works\n",
    "sample = \"This is a test sentence.\"\n",
    "tokens = word_tokenize(sample)\n",
    "print(tokens)  # Should print: ['This', 'is', 'a', 'test', 'sentence', '.']\n",
    "\n",
    "# Preprocessing function\n",
    "stemmer = PorterStemmer()\n",
    "def tokenization(txt):\n",
    "    tokens = word_tokenize(txt)\n",
    "    stemming = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stemming)\n",
    "\n",
    "# Apply to your dataframe\n",
    "df['text'] = df['text'].str.lower().replace(r'^\\w\\s', ' ').replace(r'\\n', ' ', regex=True)\n",
    "df['text'] = df['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ae873a284f49b2b12ebfe80c97e79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\music_recommendation_system\\envi_music\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nitis\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaefca53ab224e1e8cf5a2d872ed2597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881064185fd144d4a37287d62d8d7f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a7ace7c4c54430a6a570d9a5d21317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79b3faaeb9c4056b0ec20fa9dc4238f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665b4ab217004aea8845aa31dd536d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a885310c9e2c439181ea478a3c33a469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb1f7c67f694b03a11985254f49eb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce80e4f644614d0b9392545c5a5b3548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41050aaa21493d907c5bae04dd2e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e26ee8d074412281c645d6582161fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------ Generate Lyrics Embeddings ------------------\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "lyrics_embeddings = model.encode(df['text'].tolist(), convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Precompute Context Columns ------------------\n",
    "\n",
    "# ---- Mood Detection ----\n",
    "def detect_mood(text):\n",
    "    text = text.lower()\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    # Energetic keywords\n",
    "    energetic_keywords = [\"dance\", \"move\", \"jump\", \"run\", \"energy\", \"party\"]\n",
    "    if any(word in text for word in energetic_keywords):\n",
    "        return \"Energetic\"\n",
    "    elif polarity > 0.3:\n",
    "        return \"Happy\"\n",
    "    elif polarity < -0.2:\n",
    "        return \"Sad\"\n",
    "    else:\n",
    "        return \"Chill\"\n",
    "\n",
    "df['mood'] = df['text'].apply(detect_mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Activity Detection ----\n",
    "def detect_activity(text):\n",
    "    text = text.lower()\n",
    "    if any(w in text for w in [\"dance\", \"move\", \"run\", \"jump\", \"energy\"]):\n",
    "        return \"Workout\"\n",
    "    if any(w in text for w in [\"study\", \"calm\", \"focus\", \"read\", \"think\"]):\n",
    "        return \"Study\"\n",
    "    if any(w in text for w in [\"party\", \"club\", \"celebrate\", \"night\"]):\n",
    "        return \"Party\"\n",
    "    if any(w in text for w in [\"relax\", \"chill\", \"slow\", \"peace\"]):\n",
    "        return \"Relax\"\n",
    "    return \"Any\"\n",
    "\n",
    "df['activity'] = df['text'].apply(detect_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Genre Detection ----\n",
    "def detect_genre(text):\n",
    "    text = text.lower()\n",
    "    genres = [\"pop\", \"rock\", \"hip-hop\", \"jazz\", \"classical\", \"electronic\", \"country\"]\n",
    "    for g in genres:\n",
    "        if g in text:\n",
    "            return g.capitalize()\n",
    "    return \"Any\"\n",
    "\n",
    "df['genre'] = df['text'].apply(detect_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Build Similarity Matrix ------------------\n",
    "similarity_matrix = cosine_similarity(lyrics_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Recommendation Function ------------------\n",
    "def recommend_with_context(input_song, df, similarity_matrix, top_n=5, mood=\"Any\", activity=\"Any\", genre=\"Any\"):\n",
    "    try:\n",
    "        idx = df[df['song'] == input_song].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"Song '{input_song}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    sim_scores = similarity_matrix[idx]\n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:50]  # top 50 candidates\n",
    "\n",
    "    recommendations = []\n",
    "    for i in top_indices:\n",
    "        song_name = df.iloc[i].song\n",
    "\n",
    "        # Use precomputed columns\n",
    "        if mood != \"Any\" and df.iloc[i]['mood'] != mood:\n",
    "            continue\n",
    "        if activity != \"Any\" and df.iloc[i]['activity'] != activity:\n",
    "            continue\n",
    "        if genre != \"Any\" and df.iloc[i]['genre'] != genre:\n",
    "            continue\n",
    "\n",
    "        recommendations.append(song_name)\n",
    "        if len(recommendations) == top_n:\n",
    "            break\n",
    "\n",
    "    # Fallback if not enough matches\n",
    "    if len(recommendations) < top_n:\n",
    "        for i in top_indices:\n",
    "            song_name = df.iloc[i].song\n",
    "            if song_name not in recommendations:\n",
    "                recommendations.append(song_name)\n",
    "            if len(recommendations) == top_n:\n",
    "                break\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Hey Jude':\n",
      "['Another Nail In My Heart', 'You Got It', 'Honey', 'Four Letter Word', 'Hurts So Good']\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Test the Recommendation ------------------\n",
    "selected_song = 'Hey Jude'\n",
    "recommended_songs = recommend_with_context(\n",
    "    selected_song, df, similarity_matrix, top_n=5, mood=\"Any\", activity=\"Any\", genre=\"Any\"\n",
    ")\n",
    "\n",
    "print(f\"Recommendations for '{selected_song}':\")\n",
    "print(recommended_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle files saved: df.pkl and similarity.pkl\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Save Data for app.py ------------------\n",
    "with open(\"df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "with open(\"similarity.pkl\", \"wb\") as f:\n",
    "    pickle.dump(similarity_matrix, f)\n",
    "\n",
    "print(\"Pickle files saved: df.pkl and similarity.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi_music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
